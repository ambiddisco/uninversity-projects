{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf29c8d1",
   "metadata": {},
   "source": [
    "# A - Analysis of a WhatsApp chat\n",
    "### GROUP G - Authors: Alessia Bernacchia, Alexandra Biddiscombe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1604337",
   "metadata": {},
   "source": [
    "## 1. Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1671d",
   "metadata": {},
   "source": [
    "Our project consists of extracting chat data from WhatsApp, and visualising a variety of metrics about texting styles by age. As a goal of the project, we would like to prove that there are a number of differences between the ways people of different ages text, both based on our preconceptions and personal experience, and through the exploration of the data. Our various hypothesis tests and linear regression visualisations will focus mostly on the differences between people under the age of 30, and people over the age of 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890694d",
   "metadata": {},
   "source": [
    "## 2. Description of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1ad7f",
   "metadata": {},
   "source": [
    "*We asked a set of different people with different ages to provide the Whatsapp chats. All data was submitted with consent of the participants, who were requested to also submit their age for statistics purposes.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a9833",
   "metadata": {},
   "source": [
    "- **source of dataset**  \n",
    "    Multiple Whatsapp chats from people of various ages\n",
    "- **number of observation**  \n",
    "    40 chats between various age groups, for a total of 460 different people\n",
    "- **number of variables per observation**   \n",
    "    Each observation is one person's chatting information, extracted from the collected chats logs\n",
    "    We start with around 250 different people, and clean it down to 191\n",
    "- **meaning and type of the different variables**  \n",
    "    Each person (variable) is stored along with the chatting information, which in our end goal state inlcudes:\n",
    "    - **Author** : A short name acronym to separate each chatter, followed by and underscore and their age\n",
    "    - **Age** : the author's age, arguably the most important piece of information\n",
    "    - **Age_group** : which group of range 5 years their age fits into (i.e. 20 - 25)\n",
    "    - **n_letters** : the total count of letters this person sent\n",
    "    - **n_word** : the total word count sent by this person\n",
    "    - **n_emoji** : the total emoji count sent by  this person\n",
    "    - **n_Url** : the total URL count sent by this person\n",
    "    - **Media_Count** : the total number of images, audio, and other media sent by t his person\n",
    "    - **Message_Count** : the total number of distinct messages sent by this person\n",
    "    - **mean_letters_x_mess** : the average number of letters per message, calculated by taking the n_letters and dividing by the Message_Count\n",
    "    - **mean_words_x_mess** : average number of words per message\n",
    "    - **mean_emojis_x_mess** : average number of emoji per message\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94430d",
   "metadata": {},
   "source": [
    "## Dataframe creation:\n",
    "\n",
    "#### Sourcing the raw datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4583ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of dataset\n",
    "# All raw WhatsApp exports are saved locally in a folder named \"chats\"\n",
    "\n",
    "android_chats_to_analyse = [\"chats/JB_56_MKB_59.txt\", \"chats/OB_48_LC_53.txt\", \"chats/PP_35_AY_37.txt\",\n",
    "                            \"chats/FB_39_TL_34.txt\", \"chats/FB_39_SO_34.txt\", \"chats/FB_39_JB_35.txt\",\n",
    "                            \"chats/GROUP_OVER_A.txt\", \"chats/GROUP_OVER_B.txt\", \"chats/GROUP_OVER_C.txt\",\n",
    "                            \"chats/SB_23_EG_35.txt\", \"chats/RCM_21_AM_63.txt\", \"chats/RCM_21_MB_32.txt\",\n",
    "                            \"chats/MB_21_CAS_21.txt\", \"chats/MB_21_HK_21.txt\", \"chats/VAL_21_LES_21.txt\", \"chats/VAL_21_MB_21.txt\",\n",
    "                            \"chats/AB_21_YS_26.txt\", \"chats/GS_21_AM_20.txt\", \"chats/GS_21_CM_21.txt\", \"chats/GS_21_KM_22.txt\",\n",
    "                            \"chats/GS_21_SF_21.txt\", \"chats/GS_21_VM_26.txt\",\n",
    "                            \"chats/GROUP_UNDER_A.txt\", \"chats/GROUP_UNDER_B.txt\", \"chats/GROUP_UNDER_C.txt\", \"chats/GROUP_UNDER_D.txt\",\n",
    "                            \"chats/GROUP_UNDER_E.txt\", \"chats/GROUP_UNDER_F.txt\", \"chats/GROUP_UNDER_G.txt\", \"chats/GROUP_UNDER_H.txt\"]\n",
    "\n",
    "ios_chats_to_analyse = [\"chats/AZ_43_SP_48.txt\", \"chats/CL_54_NC_47.txt\", \"chats/GR_60_SP_48.txt\", \"chats/VS_36_SP_48.txt\",\n",
    "                        \"chats/FP_21_LL_22.txt\", \"chats/MM_19_AB_23.txt\", \"chats/MM_19_SM_21.txt\",\n",
    "                        \"chats/GROUP_UNDER_I.txt\", \"chats/GROUP_UNDER_L.txt\", \"chats/GROUP_UNDER_M.txt\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94f975",
   "metadata": {},
   "source": [
    "#### Importing the libraries:\n",
    "\n",
    "The first block are libraries used to create the dataframes.\\\n",
    "The second block are libraries for plotting and visualising the data.\\\n",
    "The last block is made up of the libraries used for language analysis. (reminder to remove, we most likely will not use this as it is not a letter / message counting based analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e800c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation and utility imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7dbd09",
   "metadata": {},
   "source": [
    "## 3. Data cleanup\n",
    "read the dataset in Python and take care of:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4fceb",
   "metadata": {},
   "source": [
    "When creating our chat dataframes, we want to extract the data from our initial datasets by using the system whatsapp uses to export the data. The data is exported differently when done by an Android and an iOS device, so we have to define separate code pieces to handle the different exportation methods.\n",
    "\n",
    "In both cases, we can use regex to look for the following information:\n",
    "- **Date**, the first piece of information of each interaction, which will always define the start of a datapoint;\n",
    "- **Author**, between the date and the message, which is not always present (see encryption announcements, join announcements, etc.);\n",
    "- **Message**, the body of the message, usually found after te author.\n",
    "\n",
    "To explain how to separate these pieces of information, let's take as an example the chats exported by an Android device:\n",
    "- The **date** is separated from the rest of the information by a dash (\"-\"), and will be used by future code in the format dd/mm/yy;\n",
    "- The **author** is separated from the message by a colon (\":\");\n",
    "- The **message** is any additional part of the line and future lines that do not start with a date.\n",
    "\n",
    "To make sure we obtain the correct information for each interaction, we need to be sure the regex will pick up the correct pieces each time, so we need to convert all dates to dd/mm/yy, make sure there are no \":\" in any contact name (otherwise if will split the contact name before the colon and add all the rest to the message), and add any line that does not start with a date to the text of the message above. \\\n",
    "The code for these cleaning steps is placed underneath the dataframe creation, so as to be used in the cells where it is needed.\n",
    "\n",
    "Through further data exploration and visualisation, we came to the conclusion that all analyses should be made on statistics between the ages of the people in our dataframe, and so we later remove a great deal of outside information, such as the times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40428af",
   "metadata": {},
   "source": [
    "#### Initial dataframe creation:\n",
    "The \"parse_wa_chat\" functions create an initial dataframe, using the cleaning methods described above. This is in no means the final dataframe, as we need to anonymise the data, remove all message content and add the age groups before we can perform our final analysis, so we will continue to refine the dataframe further with additional cleaning, reorganising and selection of the final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92dfb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from changer_names import change_contact_names_android, change_contact_names_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95dc20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes as input an exported whatsapp .txt file and outputs a pandas dataframe containing the columns \n",
    "# Date, Time, Author, and Message\n",
    "\n",
    "# Expected input format: a WhatsApp chat exported using an Android device.\n",
    "def parse_wa_chat_android(wa_chat_filename):\n",
    "    \n",
    "    parsed_data = [] # A list for storing the data to then be used in the pandas dataframe\n",
    "    \n",
    "    with open(wa_chat_filename, encoding=\"utf-8\") as chat:\n",
    "        chat.readline() # skip the first line, it contains information about message encoding\n",
    "        message_buffer = [] # holds any lines that are not the start of a new message\n",
    "        date, time, author = None, None, None # initialise important variables\n",
    "        while True:\n",
    "            line = chat.readline()\n",
    "            if not line:\n",
    "                break # There are no more lines, file ended, stop loop\n",
    "            line = line.strip() # remove spaces at start and end\n",
    "            \n",
    "            line = fix_faulty_contacts(line) # added because this contact name is problematic, contains \":\"\n",
    "\n",
    "            line = change_contact_names_android(line)\n",
    "            \n",
    "            if starts_with_date_and_time(line):\n",
    "                # Normalise all lines by setting date and time to same format for all files\n",
    "                if not exact_date_and_time(line):\n",
    "                    line = line[:6] + line[8:]\n",
    "                    \n",
    "                # This checks if the line starts with a timestamp\n",
    "                if len(message_buffer) > 0:\n",
    "                    parsed_data.append([date, time, author, \" \".join(message_buffer)])\n",
    "                message_buffer.clear()\n",
    "                date, time, author, message = get_data_point(line)\n",
    "                message_buffer.append(message)\n",
    "            else:\n",
    "                message_buffer.append(line)\n",
    "    chat_df = pd.DataFrame(parsed_data, columns = [\"Date\", \"Time\", \"Author\", \"Message\"])\n",
    "    \n",
    "    return chat_df\n",
    "\n",
    "\n",
    "# Checks if a given line starts with a date and time, using regex to determine\n",
    "def starts_with_date_and_time(line):\n",
    "    \n",
    "    pattern = \"^([0-9]+)(/)([0-9]+)(/)([0-9]+), ([0-9]+):([0-9]+) -\"\n",
    "    result = re.match(pattern, line)\n",
    "    \n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "# Checks if the date format has a year of length 2 digits, which is the format \"datetime\" uses\n",
    "def exact_date_and_time(line):\n",
    "    \n",
    "    pattern = \"^([0-9]+)(/)([0-9]+)(/)([0-9][0-9]), ([0-9]+):([0-9]+) -\"\n",
    "    result = re.match(pattern, line)\n",
    "    \n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "# Takes a line of the chat and log and returns the elements Date, Time, Author, and Message\n",
    "def get_data_point(line):\n",
    "    \n",
    "    split_line = line.split(\" - \", 1)\n",
    "    date_time = split_line[0]\n",
    "    \n",
    "    date, time = date_time.split(\", \", 1)\n",
    "    message = \" \".join(split_line[1:])\n",
    "    if(\":\" in message): # This indicates there is an author \n",
    "        split_message = message.split(\": \", 1)\n",
    "        author = split_message[0]\n",
    "        message = \" \".join(split_message[1:])\n",
    "    else:\n",
    "        author = None\n",
    "    \n",
    "    return date, time, author, message\n",
    "\n",
    "\n",
    "# Fix the known mistake of a contact with \":\" in it by replacing it with a functional name\n",
    "def fix_faulty_contacts(line):\n",
    "    if(\"******\" in line):\n",
    "        line = line.replace(\"******\", \"SB_23\")\n",
    "    elif(\"*******\" in line):\n",
    "        line = line.replace(\"******\", \"RCM_21\")\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee96dc1",
   "metadata": {},
   "source": [
    "*Names that gave us issues in the creation of the dataset, in the function \"fix_faulty_contacts\", have been redacted for privacy resons, and replaced with \"\\*\\*\\*\\*\\*\\*\\*\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912f6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes as input an exported whatsapp .txt file and outputs a pandas dataframe containing the columns \n",
    "# Date, Time, Author, and Message\n",
    "\n",
    "# Expected input format: a WhatsApp chat exported using an iOS device.\n",
    "def parse_wa_chat_ios(name_wa_chat_file):\n",
    "\n",
    "    # Creating a dataframe and storing all data inside that dataframe.\n",
    "    parsed_data = [] # List to keep track of data so it can be used by a Pandas dataframe\n",
    "    \n",
    "    # Uploading exported chat file\n",
    "    with open(name_wa_chat_file, encoding=\"utf-8\") as fp:\n",
    "        # Skipping first line of the file because contains information related to something about end-to-end encryption\n",
    "        fp.readline() \n",
    "        message_buffer = [] \n",
    "        date, time, author = None, None, None\n",
    "        \n",
    "        while True:\n",
    "            line = fp.readline()\n",
    "            #line = line.replace(r\"\\u200u\", \"\") \n",
    "            string_encode = line.encode(\"ascii\", \"ignore\")\n",
    "            line = string_encode.decode()\n",
    "\n",
    "            if not line: \n",
    "                break # file ended \n",
    "                \n",
    "            line = line.strip() #remove first and last space\n",
    "            line = change_contact_names_ios(line)\n",
    "\n",
    "            try:\n",
    "                if starts_with_date_and_time_ios(line): \n",
    "                    if len(message_buffer) > 0: \n",
    "                        parsed_data.append([date, time, author, ' '.join(message_buffer)])\n",
    "                    message_buffer.clear() \n",
    "                    date, time, author, message = get_data_point_ios(line) \n",
    "                    message_buffer.append(message) \n",
    "                    \n",
    "                else:\n",
    "                    message_buffer.append(line)\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    chat_df = pd.DataFrame(parsed_data, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\n",
    "\n",
    "    return chat_df\n",
    "\n",
    "def starts_with_date_and_time_ios(s):\n",
    "    patterm = '^([0-9]+)(/)([0-9]+)(/)([0-9][0-9]), ([0-9]+):([0-9][0-9]) -'\n",
    "    pattern = '^\\[([0-9]+)([\\/-])([0-9]+)([\\/-])([0-9]+)[,]? ([0-9]+):([0-9][0-9]):([0-9][0-9])?[ ]?(AM|PM|am|pm)?\\]' \n",
    "\n",
    "    result = re.match(pattern, s)\n",
    "    #print(result)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_data_point_ios(line):\n",
    "    split_line = line.split('] ')\n",
    "    date_time = split_line[0]\n",
    "    message = ' '.join(split_line[1:])\n",
    "\n",
    "    if(': ' in message ):\n",
    "        split_message = message.split(':')\n",
    "        author = split_message[0]\n",
    "        message = ' '.join(split_message[1:])\n",
    "    else:\n",
    "        author = None\n",
    "\n",
    "    date, time = date_time.split(', ')\n",
    "    if len(date) > 9:\n",
    "        date = date[1:7] + date[9:]\n",
    "    else:\n",
    "        date = date[1:]\n",
    "    \n",
    "    # Fixing the mistake that is the american date system\n",
    "    american_contacts = [\"VC_36\", \"SP_48\", \"AZ_43\", \"GR_60\"]\n",
    "    if author in american_contacts:\n",
    "        month, day, year = date.split(\"/\")\n",
    "        if len(month) == 1:\n",
    "            month = '0' + month\n",
    "        if len(day) == 1:\n",
    "            day = '0' + day\n",
    "        date = day + '/' + month + '/' + year\n",
    "\n",
    "    # Making the iOS exported time system match Android method\n",
    "    hour, minute, second = time.split(':')\n",
    "    if len(hour) == 1:\n",
    "        hour = '0' + hour\n",
    "    if 'AM' in time or 'am' in time:\n",
    "        if hour == '12':\n",
    "            hour = '00'\n",
    "    if 'PM' in time or 'pm' in time:\n",
    "        hour = str(int(hour) + 12)\n",
    "    time = hour + ':' + minute     \n",
    "\n",
    "\n",
    "    # Omitted media in the iOS format contains precise forms of media omitted, which does not match with the Android\n",
    "    # system, such as differentiating \"Omitted audio\" and \"Omitted image\". To fix this problem, we simply take any \n",
    "    # message with the common word \"omitted\" and set it to the same format as Android\n",
    "    if \"omitted\" in message:\n",
    "        message = \"<Media omitted>\"\n",
    "\n",
    "    return date, time, author, message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba646c",
   "metadata": {},
   "source": [
    "#### Additional data cleaning:\n",
    "We would like to ideally remove any recognisable information from the chat dataframes, such as content of the messages and names, using a name replacement function.       \n",
    "The code usedfor the nmae replacement is stored in a different file, for a little more anonymity, as all the contact names need to be listed to be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f376174",
   "metadata": {},
   "source": [
    "### Additional data cleaning steps:\n",
    "In this code segment, we aim to make the dataframes closer to the final use case that we are aiming for, in the following ways:\n",
    "- **Dropping all NaN** rows\n",
    "- Adding additional columns holding information about the **date**:\n",
    "    - **Day of the week**\n",
    "- Adding additional columns holding information about the  **message**:\n",
    "    - **Letters in each message**\n",
    "    - **Words in each message**\n",
    "    - **Number of URLs**\n",
    "    - **Number of media**\n",
    "    - **A list of emoji**\n",
    "    - **A list of words**\n",
    "    - **Counter for the number of messages**, at the moment this will always display 1 but will be useful for further analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8ac55",
   "metadata": {},
   "source": [
    "methods to create and populate a global dataframe of all the chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0699e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a simple dataframe as input and outputs another that is slightly better fit for the final analysis        \n",
    "def expand_df(df):\n",
    "    \n",
    "    # Drop NaN values from dataset\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Change datetype of the \"Date\" column\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%y\")\n",
    "    \n",
    "    # Adding a day column\n",
    "    weeks = {0 : 'Monday', 1 : 'Tuesday', 2 : 'Wednesday', 3 : 'Thursday', 4 : 'Friday', 5 : 'Saturday', 6: 'Sunday'}\n",
    "    df['Day'] = df['Date'].dt.weekday.map(weeks)\n",
    "    \n",
    "    # Rearrange columns for better readability\n",
    "    df = df[[\"Date\", \"Day\", \"Time\", \"Author\", \"Message\"]]\n",
    "    \n",
    "    # This is in the original code but I'm gonna skip it for now to see if it still works without:\n",
    "#     # Changing the datatype of column \"Day\".\n",
    "#     df['Day'] = df['Day'].astype('category')\n",
    "\n",
    "    # Add a letter count column for each message\n",
    "    df[\"n_letters\"] = del_omitted_media(df).apply(lambda row: len(row.Message), axis=1)\n",
    "\n",
    "    # Counting number of word's in each message, it will add extra column and store information in it.\n",
    "    df['n_word'] = del_omitted_media(df).apply( lambda row: len(row.Message.split(' ')), axis=1)\n",
    "\n",
    "    # Function to count number of links in dataset, it will add extra column and store information in it.\n",
    "    URLPATTERN = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    df['n_Url'] = df.Message.apply(lambda x: re.findall(URLPATTERN, x)).str.len()\n",
    "\n",
    "    # Count number of media in chat.\n",
    "    media_pattern_1 = r'<Media omessi>'\n",
    "    media_pattern_2 = r'<Media omitted>'\n",
    "    df['Media_Count'] = df.Message.apply(lambda x : re.findall(media_pattern_1, x)).str.len() + df.Message.apply(lambda x : re.findall(media_pattern_2, x)).str.len()\n",
    "\n",
    "    # emoji list by message\n",
    "    df[\"emoji\"] = df[\"Message\"].apply(lambda x: split_count(x))\n",
    "\n",
    "    # create word list by message\n",
    "    df[\"word\"] = del_omitted_media(df)[\"Message\"].apply(lambda x: split_in_words(x))\n",
    "\n",
    "    # usefull to count\n",
    "    df['MessageCount'] = 1\n",
    "    \n",
    "    # We decided to keep the media so as to be able to plot the frequency of messages\n",
    "    # df = del_omitted_media(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Creates a list containing all the emojis in the message\n",
    "def split_count(text):\n",
    "    \n",
    "    emoji_list = []\n",
    "    \n",
    "    data = list(text.strip(\" \"))\n",
    "\n",
    "    for word in data:\n",
    "        if any(char in emoji.EMOJI_DATA for char in word):\n",
    "            emoji_list.append(word)\n",
    "    return emoji_list\n",
    "\n",
    "\n",
    "# Creates a list of all the words in the message\n",
    "def split_in_words(text):\n",
    "    \n",
    "    #remove non alphabetical\n",
    "    text = re.sub(\"'\", \" \", text)\n",
    "    URLPATTERN = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    text = re.sub(URLPATTERN, \"\", text)\n",
    "    regex = re.compile('[^a-zA-Z àèéìòù]')\n",
    "    text = regex.sub('', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    #all in lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #create and populate list\n",
    "    words_list = text.split(\" \")\n",
    "    while(\"\" in words_list) :\n",
    "        words_list.remove(\"\")\n",
    "\n",
    "    return words_list\n",
    "\n",
    "\n",
    "# Takes a text and returns a list of words\n",
    "def split_in_words_by_lib(text):\n",
    "   \n",
    "    langdata = simplemma.load_data('it')\n",
    "    return simplemma.text_lemmatizer(text, langdata)\n",
    "\n",
    "\n",
    "# Takes a dataframe as input and returns another, stripped of omitted media (for english and italian), as output\n",
    "def del_omitted_media(df):\n",
    "    df = df[df[\"Message\"] != \"<Media omitted>\"]\n",
    "    df = df[df[\"Message\"] != \"<Media omessi>\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db34590",
   "metadata": {},
   "source": [
    "Defining which files to read\n",
    "and printing out some data as proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff1462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_df = []\n",
    "for chat in android_chats_to_analyse:\n",
    "    all_df.append(expand_df(parse_wa_chat_android(chat)))\n",
    "for chat in ios_chats_to_analyse:\n",
    "    all_df.append(expand_df(parse_wa_chat_ios(chat)))\n",
    "\n",
    "for i in range(3):\n",
    "    display(all_df[i].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53833e81",
   "metadata": {},
   "source": [
    "*Removed above output for anonymity and data privacy reasons, as it showed some message content.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b900e5",
   "metadata": {},
   "source": [
    "#### Creation of the dataset\n",
    "that contains all the messages of all the chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6782d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chats = []\n",
    "for chat in all_df:\n",
    "    chats.append(chat)\n",
    "    \n",
    "dataset = pd.concat(chats, ignore_index=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba59cb0",
   "metadata": {},
   "source": [
    "*Removed above output for anonymity and data privacy reasons, as it showed some message content.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0d0ab",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6430f4",
   "metadata": {},
   "source": [
    "At this point we have a large dataframe with all the messages of our dataset.   \n",
    "We need to organise all of them in a way useful for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833d556",
   "metadata": {},
   "source": [
    "#### delete the contact with Author = ''\n",
    "in the groups from ios chats probably there is a strange exportation of the first line (where the group is created) and create a Author with name ''   \n",
    "we have to exclude this fake-author from the statistic computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30bf502",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(dataset[dataset['Author'] == ''].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9e096",
   "metadata": {},
   "source": [
    "#### Creation of a dataframe that contains in each line the data of one person\n",
    "* **Author**: an _unique identifier_ of each person, it works as an index in this case, it is a code that contains the crypted name of a person and his age\n",
    "* **age**: it is _continuous numerical variable_ that directly records a person's age\n",
    "* **age-group**: it is _an ordinal categorical variable_ dividing the population into eight groups: 15-20 years, 21-25 years, 26-30 years, 31-35 years, 36-40 years, 41-45 years, 46-50 years, 50+ years\n",
    "* number of total **letters sent**: it is a _continuous numerical values_ that indicates the total amount of letters sent    \n",
    "* number of total **words sent**: it is a _continuous numerical values_ that indicates the total amount of words sent    \n",
    "* number of total **urls sent**: it is a _continuous numerical values_ that indicates the total amount of urls sent   \n",
    "* number of total **media sent**: it is a _continuous numerical values_ that indicates the total amount of medias sent   \n",
    "* number of total **emojis sent**: it is a _continuous numerical values_ that indicates the total amount of emojis sent   \n",
    "        \n",
    "* number of total **messages sent**: it is a _continuous numerical values_ that indicates the total amount of messages sent   \n",
    "       \n",
    "* ***average of letters for message***: it is a _continuous numerical values_ that indicates the average of letters in the messages sent   \n",
    "* ***average of words for message***: it is a _continuous numerical values_ that indicates the average of words in the messages sent   \n",
    "* ***average of emojis for message***: it is a _continuous numerical values_ that indicates the average of emojis in the messages sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745aade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with unique name of Authors\n",
    "def array_of_people(dataset):\n",
    "    people = dataset['Author'].unique()\n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed845ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter of the emoji in each line\n",
    "# because in the dataset each message contains a list of emojis,\n",
    "# that could be empty\n",
    "def count_len(list_of_lists):\n",
    "    counter = 0\n",
    "    for l in list_of_lists:\n",
    "        counter += len(l)\n",
    "    return counter\n",
    "\n",
    "# method that obtain the age from the name of the Author\n",
    "# it uses the special saving mode to extrapolate the age from the last 2 letters of the name\n",
    "def obtain_age(string_code_name):\n",
    "    number = string_code_name[-2:]\n",
    "    return int(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae951ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the dataframe where each line contains the informations of one author\n",
    "def create_dataframe_groupbyAuthor(dataset):\n",
    "\n",
    "    # initialisation with n_letters, n_word, n_url, Media_Counter, MessageCount\n",
    "    dataframe = dataset.groupby(\"Author\")[[\"n_letters\", \"n_word\", \"n_Url\", \"Media_Count\", \"MessageCount\"]].agg(sum)\n",
    "    \n",
    "    # create and insert the column age in the correct position\n",
    "    dataframe.insert(0, \"age\", dataframe.index)\n",
    "    dataframe[\"age\"] = dataframe[\"age\"].apply(obtain_age)\n",
    "    \n",
    "    # create and insert the column of 'age_group'\n",
    "    bins = [15, 20, 25, 30, 35, 40, 45, 50, float('inf')]\n",
    "    labels = ['15-20', '21-25', '26-30', '31-35', '36-40', '41-45', '46-50', '50+']\n",
    "    age_label = pd.cut(dataframe['age'], bins=bins, labels=labels)\n",
    "    dataframe.insert(1, \"age_group\", age_label)\n",
    "    \n",
    "    # create a dataframe with all the emoji's lists\n",
    "    n_emojis = dataset.groupby(\"Author\")[[\"emoji\"]].agg(list)\n",
    "    n_emojis['emoji'] = n_emojis['emoji'].apply(count_len)\n",
    "    # insert the column in the correct position\n",
    "    # it is a list of lists that contains emojis\n",
    "    dataframe.insert(4, \"n_emoji\", dataset.groupby(\"Author\")[[\"emoji\"]].agg(list))\n",
    "\n",
    "    # modify the dataframe applying to the column the aggregation made\n",
    "    dataframe['n_emoji'] = dataframe['n_emoji'].apply(count_len)\n",
    "\n",
    "    # add the mean of letters used for message\n",
    "    dataframe['mean_letters_x_mess'] = round(dataframe['n_letters'] / dataframe['MessageCount'], 2)\n",
    "\n",
    "    # add the mean of words used for message\n",
    "    dataframe['mean_words_x_mess'] = round(dataframe['n_word'] / dataframe['MessageCount'], 2)\n",
    "\n",
    "    # add the mean of emojis used for message\n",
    "    dataframe['mean_emojis_x_mess'] = round(dataframe['n_emoji'] / dataframe['MessageCount'], 2)\n",
    "\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5d33403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_of_people(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b85106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4466/2606073340.py:5: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  dataframe = dataset.groupby(\"Author\")[[\"n_letters\", \"n_word\", \"n_Url\", \"Media_Count\", \"MessageCount\"]].agg(sum)\n"
     ]
    }
   ],
   "source": [
    "# creation of the dataframe\n",
    "dataframe = create_dataframe_groupbyAuthor(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b293f",
   "metadata": {},
   "source": [
    "#### delete the people with too small number of messages\n",
    "we choose to accept the authors that have written more than 30 messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7a0e2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4466/1331105127.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dataframe.count()[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of total lines in the initial dataframe\n",
    "dataframe.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54535507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of messages that a person need at least to be considered in the statistics\n",
    "min_messages = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8130ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe[dataframe[\"MessageCount\"]>=min_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091268f",
   "metadata": {},
   "source": [
    "#### split the dataframe in two dataframes (over and under 30)\n",
    "creation of two differents dataframes only with the people who have enough number of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a25118c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4466/1506957158.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dataframe.count()[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of total lines in the initial dataframe\n",
    "dataframe.count()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3435921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4466/3177705200.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(df_over_30.count()[0])\n"
     ]
    }
   ],
   "source": [
    "# dataframe for over 30s\n",
    "df_over_30 = dataframe[(dataframe[\"age\"]>=30) & (dataframe[\"MessageCount\"]>=min_messages)]\n",
    "print(df_over_30.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa56d92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_letters</th>\n",
       "      <th>n_word</th>\n",
       "      <th>n_emoji</th>\n",
       "      <th>n_Url</th>\n",
       "      <th>Media_Count</th>\n",
       "      <th>MessageCount</th>\n",
       "      <th>mean_letters_x_mess</th>\n",
       "      <th>mean_words_x_mess</th>\n",
       "      <th>mean_emojis_x_mess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.327273</td>\n",
       "      <td>9880.509091</td>\n",
       "      <td>1932.327273</td>\n",
       "      <td>32.472727</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>36.472727</td>\n",
       "      <td>167.127273</td>\n",
       "      <td>69.923273</td>\n",
       "      <td>13.219455</td>\n",
       "      <td>0.322909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.198391</td>\n",
       "      <td>16360.187475</td>\n",
       "      <td>3372.212352</td>\n",
       "      <td>59.392871</td>\n",
       "      <td>6.441396</td>\n",
       "      <td>79.885996</td>\n",
       "      <td>295.096912</td>\n",
       "      <td>40.968667</td>\n",
       "      <td>7.542703</td>\n",
       "      <td>0.427532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>8.730000</td>\n",
       "      <td>1.980000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.500000</td>\n",
       "      <td>1765.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>37.385000</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>0.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>3918.000000</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>65.690000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.500000</td>\n",
       "      <td>9301.000000</td>\n",
       "      <td>1930.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>91.315000</td>\n",
       "      <td>17.220000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>91943.000000</td>\n",
       "      <td>18809.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>1780.000000</td>\n",
       "      <td>207.190000</td>\n",
       "      <td>39.730000</td>\n",
       "      <td>2.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age     n_letters        n_word     n_emoji      n_Url  \\\n",
       "count  55.000000     55.000000     55.000000   55.000000  55.000000   \n",
       "mean   42.327273   9880.509091   1932.327273   32.472727   3.090909   \n",
       "std     7.198391  16360.187475   3372.212352   59.392871   6.441396   \n",
       "min    30.000000    890.000000    173.000000    0.000000   0.000000   \n",
       "25%    37.500000   1765.000000    340.000000    4.000000   0.000000   \n",
       "50%    42.000000   3918.000000    744.000000   11.000000   1.000000   \n",
       "75%    46.500000   9301.000000   1930.000000   37.000000   4.000000   \n",
       "max    63.000000  91943.000000  18809.000000  352.000000  43.000000   \n",
       "\n",
       "       Media_Count  MessageCount  mean_letters_x_mess  mean_words_x_mess  \\\n",
       "count    55.000000     55.000000            55.000000          55.000000   \n",
       "mean     36.472727    167.127273            69.923273          13.219455   \n",
       "std      79.885996    295.096912            40.968667           7.542703   \n",
       "min       0.000000     25.000000             8.730000           1.980000   \n",
       "25%       3.000000     34.500000            37.385000           7.480000   \n",
       "50%       7.000000     62.000000            65.690000          12.350000   \n",
       "75%      27.000000    143.500000            91.315000          17.220000   \n",
       "max     508.000000   1780.000000           207.190000          39.730000   \n",
       "\n",
       "       mean_emojis_x_mess  \n",
       "count           55.000000  \n",
       "mean             0.322909  \n",
       "std              0.427532  \n",
       "min              0.000000  \n",
       "25%              0.065000  \n",
       "50%              0.220000  \n",
       "75%              0.440000  \n",
       "max              2.710000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over_30.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4beb0b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4466/1005373609.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(df_under_30.count()[0])\n"
     ]
    }
   ],
   "source": [
    "# dataframe for under 30s\n",
    "df_under_30 = dataframe[(dataframe[\"age\"]<30) & (dataframe[\"MessageCount\"]>=min_messages)]\n",
    "print(df_under_30.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0a110f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_letters</th>\n",
       "      <th>n_word</th>\n",
       "      <th>n_emoji</th>\n",
       "      <th>n_Url</th>\n",
       "      <th>Media_Count</th>\n",
       "      <th>MessageCount</th>\n",
       "      <th>mean_letters_x_mess</th>\n",
       "      <th>mean_words_x_mess</th>\n",
       "      <th>mean_emojis_x_mess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>1.360000e+02</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.117647</td>\n",
       "      <td>2.944379e+04</td>\n",
       "      <td>5983.610294</td>\n",
       "      <td>84.926471</td>\n",
       "      <td>9.639706</td>\n",
       "      <td>82.882353</td>\n",
       "      <td>799.139706</td>\n",
       "      <td>36.434412</td>\n",
       "      <td>7.521176</td>\n",
       "      <td>0.075588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.322383</td>\n",
       "      <td>1.201824e+05</td>\n",
       "      <td>23791.426210</td>\n",
       "      <td>424.858349</td>\n",
       "      <td>55.788048</td>\n",
       "      <td>292.859771</td>\n",
       "      <td>2803.645381</td>\n",
       "      <td>17.993952</td>\n",
       "      <td>3.208407</td>\n",
       "      <td>0.169953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.990000e+02</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.780000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.767250e+03</td>\n",
       "      <td>360.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>23.992500</td>\n",
       "      <td>5.277500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.403000e+03</td>\n",
       "      <td>883.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>32.470000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>9.918500e+03</td>\n",
       "      <td>2217.500000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>298.500000</td>\n",
       "      <td>41.980000</td>\n",
       "      <td>8.442500</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.030826e+06</td>\n",
       "      <td>201162.000000</td>\n",
       "      <td>3398.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>1882.000000</td>\n",
       "      <td>24675.000000</td>\n",
       "      <td>113.980000</td>\n",
       "      <td>21.620000</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     n_letters         n_word      n_emoji       n_Url  \\\n",
       "count  136.000000  1.360000e+02     136.000000   136.000000  136.000000   \n",
       "mean    21.117647  2.944379e+04    5983.610294    84.926471    9.639706   \n",
       "std      2.322383  1.201824e+05   23791.426210   424.858349   55.788048   \n",
       "min     16.000000  4.990000e+02     117.000000     0.000000    0.000000   \n",
       "25%     20.000000  1.767250e+03     360.250000     0.000000    0.000000   \n",
       "50%     21.000000  4.403000e+03     883.000000     0.000000    1.000000   \n",
       "75%     21.000000  9.918500e+03    2217.500000     5.250000    3.000000   \n",
       "max     29.000000  1.030826e+06  201162.000000  3398.000000  627.000000   \n",
       "\n",
       "       Media_Count  MessageCount  mean_letters_x_mess  mean_words_x_mess  \\\n",
       "count   136.000000    136.000000           136.000000         136.000000   \n",
       "mean     82.882353    799.139706            36.434412           7.521176   \n",
       "std     292.859771   2803.645381            17.993952           3.208407   \n",
       "min       0.000000     25.000000            13.780000           3.180000   \n",
       "25%       3.000000     55.000000            23.992500           5.277500   \n",
       "50%       9.000000    116.500000            32.470000           6.950000   \n",
       "75%      25.750000    298.500000            41.980000           8.442500   \n",
       "max    1882.000000  24675.000000           113.980000          21.620000   \n",
       "\n",
       "       mean_emojis_x_mess  \n",
       "count          136.000000  \n",
       "mean             0.075588  \n",
       "std              0.169953  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.050000  \n",
       "max              1.150000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under_30.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c20ee2",
   "metadata": {},
   "source": [
    "#### creation of a dataset where each line is one of the group-age\n",
    "* index is the **age-group**: the indexing variable that is _an ordinal categorical variable_ dividing the population into eight groups: 15-20 years, 21-25 years, 26-30 years, 31-35 years, 36-40 years, 41-45 years, 46-50 years, 50+ years\n",
    "    \n",
    "* number of **people**: a _continuous numerical variable_ that indicates the sample size of each group of age\n",
    "* number of total **letters sent**:  a _continuous numerical values_ that indicates the total amount of letters sent by the group    \n",
    "* number of total **words sent**:  a _continuous numerical values_ that indicates the total amount of words sent by the group   \n",
    "* number of total **urls sent**:  a _continuous numerical values_ that indicates the total amount of urls sent by the group   \n",
    "* number of total **media sent**:  a _continuous numerical values_ that indicates the total amount of media sent by the group   \n",
    "* number of total **emojis sent**:  a _continuous numerical values_ that indicates the total amount of emojis sent by the group   \n",
    "        \n",
    "* number of total **messages sent**:  a _continuous numerical values_ that indicates the total amount of messages sent by the group   \n",
    "       \n",
    "* ***average of letters for message***: a _continuous numerical values_ that indicates the average of letters in the messages sent by the group    \n",
    "* ***average of words for message***: a _continuous numerical values_ that indicates the average of words in the messages sent by the group   \n",
    "* ***average of emojis for message***: a _continuous numerical values_ that indicates the emojis of letters in the messages sent by the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03d3d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the dataframe where each line contains the informations of one author\n",
    "def create_dataframe_groupbyAgeGroup(dataset):\n",
    "\n",
    "    # initialisation with n_letters, n_word, n_url, Media_Counter, MessageCount\n",
    "    dataframe = dataset.groupby(\"age_group\")[[\"n_letters\", \"n_word\", \"n_Url\", \"Media_Count\", \"n_emoji\", \"MessageCount\"]].agg(sum)\n",
    "\n",
    "    # add the mean of letters used for message\n",
    "    dataframe['mean_letters_x_mess'] = round(dataframe['n_letters'] / dataframe['MessageCount'], 2)\n",
    "\n",
    "    # add the mean of words used for message\n",
    "    dataframe['mean_words_x_mess'] = round(dataframe['n_word'] / dataframe['MessageCount'], 2)\n",
    "\n",
    "    # add the mean of emojis used for message\n",
    "    dataframe['mean_emojis_x_mess'] = round(dataframe['n_emoji'] / dataframe['MessageCount'], 2)\n",
    "    \n",
    "    # create and insert the column people in the correct position\n",
    "    # create a serie with a list of information for all group of age\n",
    "    # and after applies the len on one column --> to obtain the number of people\n",
    "    n_people = dataset.groupby(\"age_group\").agg(list)[\"n_letters\"].apply(len)\n",
    "    dataframe.insert(0, \"n_people\", n_people)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "000e3fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4466/1985088094.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dataframe = dataset.groupby(\"age_group\")[[\"n_letters\", \"n_word\", \"n_Url\", \"Media_Count\", \"n_emoji\", \"MessageCount\"]].agg(sum)\n",
      "/tmp/ipykernel_4466/1985088094.py:5: FutureWarning: The provided callable <built-in function sum> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  dataframe = dataset.groupby(\"age_group\")[[\"n_letters\", \"n_word\", \"n_Url\", \"Media_Count\", \"n_emoji\", \"MessageCount\"]].agg(sum)\n",
      "/tmp/ipykernel_4466/1985088094.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  n_people = dataset.groupby(\"age_group\").agg(list)[\"n_letters\"].apply(len)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_people</th>\n",
       "      <th>n_letters</th>\n",
       "      <th>n_word</th>\n",
       "      <th>n_Url</th>\n",
       "      <th>Media_Count</th>\n",
       "      <th>n_emoji</th>\n",
       "      <th>MessageCount</th>\n",
       "      <th>mean_letters_x_mess</th>\n",
       "      <th>mean_words_x_mess</th>\n",
       "      <th>mean_emojis_x_mess</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15-20</th>\n",
       "      <td>58</td>\n",
       "      <td>572276.0</td>\n",
       "      <td>119591.0</td>\n",
       "      <td>769</td>\n",
       "      <td>2666</td>\n",
       "      <td>10</td>\n",
       "      <td>17723</td>\n",
       "      <td>32.29</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21-25</th>\n",
       "      <td>67</td>\n",
       "      <td>3376660.0</td>\n",
       "      <td>683010.0</td>\n",
       "      <td>518</td>\n",
       "      <td>8474</td>\n",
       "      <td>11338</td>\n",
       "      <td>89201</td>\n",
       "      <td>37.85</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26-30</th>\n",
       "      <td>13</td>\n",
       "      <td>57648.0</td>\n",
       "      <td>11627.0</td>\n",
       "      <td>25</td>\n",
       "      <td>132</td>\n",
       "      <td>202</td>\n",
       "      <td>1831</td>\n",
       "      <td>31.48</td>\n",
       "      <td>6.35</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31-35</th>\n",
       "      <td>7</td>\n",
       "      <td>70842.0</td>\n",
       "      <td>14108.0</td>\n",
       "      <td>13</td>\n",
       "      <td>302</td>\n",
       "      <td>432</td>\n",
       "      <td>2079</td>\n",
       "      <td>34.08</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36-40</th>\n",
       "      <td>13</td>\n",
       "      <td>99423.0</td>\n",
       "      <td>19118.0</td>\n",
       "      <td>32</td>\n",
       "      <td>902</td>\n",
       "      <td>657</td>\n",
       "      <td>2262</td>\n",
       "      <td>43.95</td>\n",
       "      <td>8.45</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41-45</th>\n",
       "      <td>17</td>\n",
       "      <td>103752.0</td>\n",
       "      <td>18987.0</td>\n",
       "      <td>49</td>\n",
       "      <td>224</td>\n",
       "      <td>510</td>\n",
       "      <td>1237</td>\n",
       "      <td>83.87</td>\n",
       "      <td>15.35</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46-50</th>\n",
       "      <td>9</td>\n",
       "      <td>139038.0</td>\n",
       "      <td>28118.0</td>\n",
       "      <td>12</td>\n",
       "      <td>304</td>\n",
       "      <td>104</td>\n",
       "      <td>1636</td>\n",
       "      <td>84.99</td>\n",
       "      <td>17.19</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50+</th>\n",
       "      <td>7</td>\n",
       "      <td>128144.0</td>\n",
       "      <td>25490.0</td>\n",
       "      <td>63</td>\n",
       "      <td>274</td>\n",
       "      <td>83</td>\n",
       "      <td>1906</td>\n",
       "      <td>67.23</td>\n",
       "      <td>13.37</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n_people  n_letters    n_word  n_Url  Media_Count  n_emoji  \\\n",
       "age_group                                                               \n",
       "15-20            58   572276.0  119591.0    769         2666       10   \n",
       "21-25            67  3376660.0  683010.0    518         8474    11338   \n",
       "26-30            13    57648.0   11627.0     25          132      202   \n",
       "31-35             7    70842.0   14108.0     13          302      432   \n",
       "36-40            13    99423.0   19118.0     32          902      657   \n",
       "41-45            17   103752.0   18987.0     49          224      510   \n",
       "46-50             9   139038.0   28118.0     12          304      104   \n",
       "50+               7   128144.0   25490.0     63          274       83   \n",
       "\n",
       "           MessageCount  mean_letters_x_mess  mean_words_x_mess  \\\n",
       "age_group                                                         \n",
       "15-20             17723                32.29               6.75   \n",
       "21-25             89201                37.85               7.66   \n",
       "26-30              1831                31.48               6.35   \n",
       "31-35              2079                34.08               6.79   \n",
       "36-40              2262                43.95               8.45   \n",
       "41-45              1237                83.87              15.35   \n",
       "46-50              1636                84.99              17.19   \n",
       "50+                1906                67.23              13.37   \n",
       "\n",
       "           mean_emojis_x_mess  \n",
       "age_group                      \n",
       "15-20                    0.00  \n",
       "21-25                    0.13  \n",
       "26-30                    0.11  \n",
       "31-35                    0.21  \n",
       "36-40                    0.29  \n",
       "41-45                    0.41  \n",
       "46-50                    0.06  \n",
       "50+                      0.04  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_age = create_dataframe_groupbyAgeGroup(dataframe)\n",
    "df_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f1928",
   "metadata": {},
   "source": [
    "### Export of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e7a5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.copy()\n",
    "dataframe.sort_values(by=['age'], inplace= True)\n",
    "\n",
    "df_under_30 = df_under_30.copy()\n",
    "df_under_30.sort_values(by=['age'], inplace= True)\n",
    "\n",
    "df_over_30 = df_over_30.copy()\n",
    "df_over_30.sort_values(by=['age'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bcfd59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"dataset\"):\n",
    "    os.mkdir('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "822bfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('dataset/complete_dataframe.csv')\n",
    "df_age.to_csv('dataset/age_data.csv')\n",
    "df_over_30.to_csv('dataset/over30_data.csv')\n",
    "df_under_30.to_csv('dataset/under30_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
